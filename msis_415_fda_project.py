# -*- coding: utf-8 -*-
"""MSIS 415 FDA PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EWsW6Chzdt2fV-1kBgqiAMtJj83VAg7P

# Food Recall FDA Data Analysis Project
#### This project analyzes food recall data collected from the openFDA API.  
The main objectives are:

- Understand the trend of food recalls over time.
- Predict the number of food recalls using machine learning.
- Analyze the distribution of recall severity classifications.
"""

# Import libraries needed for API request and data
import requests
import pandas as pd

"""We used the openFDA API to collect food recall data.  
Using Python and the `requests` library, we fetched the data in JSON format and converted it into a pandas DataFrame for easier handling and analysis.
"""

# Set up the URL to call the openFDA API
url = 'https://api.fda.gov/food/enforcement.json?limit=1000'
# Send a GET request to the API
response = requests.get(url)
response.raise_for_status()
data = response.json()
# we used Python and the `requests` library to automatically fetch the data in JSON format. So we didn't need to manually crawl web pages or use Selenium, because the API gave us direct access to the information we needed. After fetching the data, we processed it to prepare for the analysis part.

# Convert JSON to pandas DataFrame (basic style)
results = data['results']  # Get the 'results' part from JSON
recall_data = pd.DataFrame(results)  # Create DataFrame

# Show DataFrame
recall_data

"""## Clean and Prepare the Data
In this part, we will:
- Change the 'recall_initiation_date' from numbers to real dates.
- Create a new column 'year' from the date.
- Check if there is any missing data.
"""

# Import the library
import sqlite3

# Convert 'recall_initiation_date' from numbers to real dates
recall_data['recall_initiation_date'] = pd.to_datetime(recall_data['recall_initiation_date'], format='%Y%m%d')

# Create a new column 'year' from the date
recall_data['year'] = recall_data['recall_initiation_date'].dt.year

# Check if there is any missing data
recall_data.isnull().sum()

"""###### The important columns we will use like 'recall_initiation_date', 'year', 'product_type', and 'classification', have no missing values. And some other columns have missing data, but we do not use them in our project.
###### After checking for missing data, we confirmed that important columns such as 'recall_initiation_date', 'year', 'product_type', and 'classification' have no missing values. Therefore, we proceeded with inserting the cleaned data into the database.

### Prepare the database
"""

# Connect to a new SQLite database
db = sqlite3.connect('recall_data.db')

# Create a cursor
cur = db.cursor()

# Create a table
cur.execute('''
CREATE TABLE IF NOT EXISTS recalls (
    recall_number TEXT,
    recalling_firm TEXT,
    product_type TEXT,
    classification TEXT,
    recall_initiation_date TEXT,
    year INTEGER
)
''')

# Save (commit) the changes
db.commit()

"""## Insert the Cleaned Data into the Database
After preparing the data, we saved it into an SQLite database.  
This helps organize the information neatly and makes it easier to use later for analysis and visualization.  
We used a loop to insert each row of the cleaned recall data into the database.

"""

# Prepare SQL query
query = '''
INSERT INTO recalls
VALUES (?, ?, ?, ?, ?, ?)
'''

# Insert each row
for index, row in recall_data.iterrows():
    cur.execute(query, (
        row['recall_number'],
        row['recalling_firm'],
        row['product_type'],
        row['classification'],
        str(row['recall_initiation_date'])[:10],
        row['year']
    ))

# Save changes
db.commit()

"""## Retrieve and Prepare the Data for Analysis

We select all records from the 'recalls' table in the database. Then, we convert the data into a pandas DataFrame so that we can easily perform data analysis and visualization.
"""

# Select all data from the recalls table
cur.execute('SELECT * FROM recalls')

# Fetch all results
rows = cur.fetchall()

# Get column names automatically
columns = [description[0] for description in cur.description]

# Convert to pandas DataFrame
import pandas as pd
recalls_df = pd.DataFrame(rows, columns=columns)

# Show the DataFrame
recalls_df.head(1000)

"""# Q1: Plot the trend of recall numbers over the year
We looked at how the number of food recalls changed over the years.  
We grouped the data by year and made a line chart to see if the recalls were going up or down over time.
"""

# Group data by 'year' and count the number of recalls
recall_trend = recalls_df.groupby('year').size().reset_index(name='recall_count')
recall_trend

# Import matplotlib for plotting
import matplotlib.pyplot as plt

# Plot the trend
plt.figure(figsize=(10, 6))
plt.plot(recall_trend['year'], recall_trend['recall_count'], marker='o')
plt.title('Trend of Food Recalls Over Time')
plt.xlabel('Year')
plt.ylabel('Number of Recalls')
plt.grid(True)
plt.show()

"""# Q2: Predict the number of recalls using Linear Regression
We used a Linear Regression model to predict how many recalls happen each year.
First, we split the data into training and testing sets.
Then, we trained the model and tested how well it worked by checking the Mean Squared Error (MSE) and R² score.
Finally, we made a plot to compare the actual and predicted numbers of recalls.
"""

# Import libraries needed for Linear Regression
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Define the prediction function
def predict_recall_trend():
    # Group data by year and count number of recalls
    yearly_recalls = recalls_df.groupby('year').size().reset_index(name='count')
    X = yearly_recalls['year'].values.reshape(-1, 1)
    y = yearly_recalls['count'].values

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train linear regression model
    model = LinearRegression()
    model.fit(X_train, y_train)

    # Make predictions
    y_pred = model.predict(X_test)

    # Plot results
    plt.figure(figsize=(10, 6))
    plt.scatter(X_test, y_test, color='blue', label='Actual')
    plt.plot(X_test, y_pred, color='red', linewidth=2, label='Predicted')
    plt.title('Recall Prediction with Linear Regression')
    plt.xlabel('Year')
    plt.ylabel('Number of Recalls')
    plt.legend()
    plt.grid(True)
    plt.show()

    # Evaluate model
    print(f"Model Coefficient: {model.coef_[0]}")
    print(f"Model Intercept: {model.intercept_}")
    print(f"Mean Squared Error: {mean_squared_error(y_test, y_pred)}")
    print(f"R² Score: {r2_score(y_test, y_pred)}")

predict_recall_trend()

"""# Q3: Analyze the distribution of recall severity classifications
We counted how many recalls belong to each classification type (Class I, II, III).  
We made a bar chart and a pie chart to show the differences and better understand the severity of the recalls.
"""

# Import libraries needed for plotting
import matplotlib.pyplot as plt

def analyze_recall_classification():
    # Count number of recalls per classification
    classification_counts = recalls_df['classification'].value_counts()

    # Plot bar chart
    plt.figure(figsize=(10, 6))
    classification_counts.plot(kind='bar', color='skyblue')
    plt.title('Recalls by Classification')
    plt.xlabel('Classification')
    plt.ylabel('Number of Recalls')
    plt.grid(axis='y')
    plt.xticks(rotation=45)
    plt.show()

    # Plot pie chart
    plt.figure(figsize=(8, 8))
    classification_counts.plot(kind='pie', autopct='%1.1f%%', startangle=140)
    plt.title('Recalls by Classification (Pie Chart)')
    plt.ylabel('')  # Remove y-axis label
    plt.show()

# Execute the function
analyze_recall_classification()

